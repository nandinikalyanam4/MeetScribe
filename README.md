# AI-Powered Meeting Transcription & Analysis

This is an intelligent audio recording and transcription application that automatically transcribes meetings, identifies speakers, and generates structured notes with action items using AI.

## ğŸ¯ Features

- **ğŸ¤ Real-time Audio Recording** - Capture audio directly from your browser
- **ğŸ™ï¸ Speaker Diarization** - Automatically identifies and labels different speakers
- **ğŸ“ AI-Generated Notes** - Uses Google Gemini to create structured meeting summaries
- **âœ… Action Items Extraction** - Automatically identifies and formats action items from conversations
- **â˜ï¸ Cloud Storage** - Automatic backup to Supabase Storage when backend is unavailable
- **ğŸ” Search Functionality** - Search through your recordings by title or transcript
- **ğŸ“± Responsive Design** - Modern, dark-themed UI that works on all devices

## ğŸ› ï¸ Tech Stack

### Frontend
- **React 19** with TypeScript
- **Vite** for build tooling
- **Lucide React** for icons
- **Supabase** for cloud storage fallback

### Backend
- **FastAPI** - Python web framework
- **WhisperX** - Advanced speech recognition with word-level timestamps
- **pyannote.audio** - Speaker diarization pipeline
- **Google Gemini 3 Flash** - AI-powered note generation via LangChain
- **Supabase** - Cloud storage integration

## ğŸ“‹ Prerequisites

- **Python 3.8+**
- **Node.js 18+** and npm
- **FFmpeg** - Required for audio processing
- **CUDA-capable GPU** (optional but recommended for faster processing)
- **Google API Key** - For Gemini AI features
- **Supabase Account** (optional, for cloud storage)

## ğŸš€ Installation

### 1. Clone the Repository

```bash
git clone <repository-url>
cd ReadAI
```

### 2. Backend Setup

```bash
cd Backend

# Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install PyTorch with CUDA support (if you have a compatible GPU)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# Install other dependencies
pip install -r requirements.txt
```

**Note:** For CPU-only installation, install PyTorch without CUDA:
```bash
pip install torch torchvision torchaudio
```

### 3. Frontend Setup

```bash
cd ReadAI

# Install dependencies
npm install
```

### 4. Environment Variables

Create a `.env` file in the `Backend` directory:

```env
# Supabase Configuration (optional)
SUPABASE_URL=your_supabase_url
SUPABASE_ANON_KEY=your_supabase_anon_key

# Google Gemini API Key (required for note generation)
GOOGLE_API_KEY=your_google_api_key
```

Create a `.env` file in the `ReadAI` directory:

```env
# Supabase Configuration (optional, for cloud storage fallback)
VITE_SUPABASE_URL=your_supabase_url
VITE_SUPABASE_ANON_KEY=your_supabase_anon_key

# Backend API URL
VITE_API_URL=http://localhost:8000
```

## ğŸƒ Running the Application

### Start the Backend Server

```bash
cd Backend
python main.py
```

The API will be available at `http://localhost:8000`

### Start the Frontend Development Server

```bash
cd ReadAI
npm run dev
```

The frontend will be available at `http://localhost:5173` (or the port Vite assigns)

## ğŸ“ Project Structure

```
ReadAI/
â”œâ”€â”€ Backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI application
â”‚   â”œâ”€â”€ requirements.txt     # Python dependencies
â”‚   â”œâ”€â”€ uploads/             # Temporary audio file storage
â”‚   â”œâ”€â”€ outputs/             # Processed transcription outputs
â”‚   â””â”€â”€ recordings.json       # Recording metadata database
â”‚
â”œâ”€â”€ ReadAI/
â”‚   â”œâ”€â”€ src/                 # React source files
â”‚   â”œâ”€â”€ components/           # React components
â”‚   â”‚   â”œâ”€â”€ Recorder.tsx     # Audio recording component
â”‚   â”‚   â””â”€â”€ RecordingCard.tsx # Recording list item component
â”‚   â”œâ”€â”€ services/             # API and service integrations
â”‚   â”‚   â”œâ”€â”€ apiService.ts    # Backend API client
â”‚   â”‚   â”œâ”€â”€ SupabaseService.ts # Cloud storage service
â”‚   â”‚   â””â”€â”€ audioConverter.ts # Audio format conversion
â”‚   â”œâ”€â”€ App.tsx              # Main application component
â”‚   â”œâ”€â”€ types.ts             # TypeScript type definitions
â”‚   â””â”€â”€ package.json         # Node.js dependencies
â”‚
â””â”€â”€ README.md                # This file
```

## ğŸ”Œ API Endpoints

### Recordings
- `GET /recordings` - Get all recordings
- `POST /recordings` - Save a new recording
- `DELETE /recordings/{id}` - Delete a recording

### Transcription
- `POST /transcribe` - Upload audio file for transcription
  - Parameters: `file` (audio file), `formats` (txt,json,srt), `recording_id` (optional)
  - Returns: `job_id` for tracking

- `GET /status/{job_id}` - Get transcription job status
  - Returns: Processing status, progress, and results

- `GET /download/{job_id}/{format}` - Download processed file (txt, json, or srt)

### AI Generation
- `POST /generate/notes/{job_id}` - Generate meeting notes from transcription
  - Returns: Structured notes with recap, chapters, action items, and key questions

### Health
- `GET /` - Service information
- `GET /health` - Health check endpoint

## ğŸ¨ Usage

1. **Start Recording**: Click the record button in the main interface
2. **Stop Recording**: Click stop when finished
3. **Name Your Recording**: Enter a descriptive name
4. **Process Audio**: Click "Analyze Audio" to start transcription and AI analysis
5. **View Results**: Once processing completes, view the transcript, notes, and action items
6. **Search**: Use the search bar to find recordings by title or content
7. **Edit Titles**: Hover over a recording title and click the edit icon to rename

## ğŸ”’ Security Notes

- All API keys and sensitive credentials are loaded from environment variables
- Never commit `.env` files to version control
- Supabase anon keys are safe for client-side use (they have Row Level Security)
- Google API keys should be kept secure and not exposed in client-side code


## ğŸ“ Development

### Building for Production

**Frontend:**
```bash
cd ReadAI
npm run build
```

## ğŸ™ Acknowledgments

- [WhisperX](https://github.com/m-bain/whisperX) for transcription
- [pyannote.audio](https://github.com/pyannote/pyannote-audio) for speaker diarization
- [Google Gemini](https://deepmind.google/technologies/gemini/) for AI-powered analysis
- [Supabase](https://supabase.com/) for cloud storage

---

**Note:** This application processes audio locally and requires significant computational resources. For production use, consider deploying to a server with GPU support for optimal performance.

